# app.py
from flask import Flask, render_template, request, jsonify
import requests
import json
from datetime import datetime
import time

app = Flask(__name__)

# Ollama APIé…ç½®
OLLAMA_BASE_URL = "http://localhost:11434"  # é»˜è®¤Ollamaåœ°å€

class OllamaChatAgent:
    def __init__(self):
        self.available_models = self.get_available_models()
        self.current_model = "deepseek-r1:7b"  # é»˜è®¤æ¨¡å‹
        
    def get_available_models(self):
        """è·å–å¯ç”¨çš„Ollamaæ¨¡å‹"""
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags")
            if response.status_code == 200:
                models_data = response.json()
                return [model["name"] for model in models_data.get("models", [])]
            else:
                print(f"æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨: {response.status_code}")
                return ["llama2"]  # é»˜è®¤å›é€€
        except Exception as e:
            print(f"è·å–æ¨¡å‹æ—¶å‡ºé”™: {e}")
            return ["llama2"]  # é»˜è®¤å›é€€
    
    def chat(self, message, conversation_history=None, model=None):
        """ä¸Ollamaæ¨¡å‹å¯¹è¯"""
        if model is None:
            model = self.current_model
            
        # æ„å»ºå¯¹è¯å†å²
        messages = []
        if conversation_history:
            messages.extend(conversation_history)
        
        # æ·»åŠ å½“å‰æ¶ˆæ¯
        messages.append({"role": "user", "content": message})
        
        try:
            # è°ƒç”¨Ollama API
            payload = {
                "model": model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "top_k": 40
                }
            }
            
            start_time = time.time()
            response = requests.post(
                f"{OLLAMA_BASE_URL}/api/chat",
                json=payload,
                timeout=60  # 60ç§’è¶…æ—¶
            )
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                assistant_reply = result["message"]["content"]
                
                # æ›´æ–°å¯¹è¯å†å²
                if conversation_history is not None:
                    conversation_history.append({"role": "user", "content": message})
                    conversation_history.append({"role": "assistant", "content": assistant_reply})
                
                return {
                    "success": True,
                    "reply": assistant_reply,
                    "response_time": f"{response_time:.2f}s",
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "model": model
                }
            else:
                return {
                    "success": False,
                    "error": f"Ollama APIé”™è¯¯: {response.status_code} - {response.text}",
                    "timestamp": datetime.now().strftime("%H:%M:%S")
                }
                
        except requests.exceptions.ConnectionError:
            return {
                "success": False,
                "error": "æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ã€‚è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œã€‚",
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"è¯·æ±‚å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().strftime("%H:%M:%S")
            }
    
    def get_models(self):
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return self.available_models
    
    def set_model(self, model_name):
        """è®¾ç½®å½“å‰æ¨¡å‹"""
        if model_name in self.available_models:
            self.current_model = model_name
            return True
        return False

# åˆå§‹åŒ–èŠå¤©ä»£ç†
agent = OllamaChatAgent()

@app.route('/')
def index():
    return render_template('index.html', models=agent.get_models())

@app.route('/api/chat', methods=['POST'])
def chat_api():
    data = request.get_json()
    user_message = data.get('message', '')
    model = data.get('model', agent.current_model)
    
    if not user_message.strip():
        return jsonify({
            "success": False,
            "error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"
        })
    
    # è®¾ç½®æ¨¡å‹
    if model != agent.current_model:
        agent.set_model(model)
    
    result = agent.chat(user_message)
    return jsonify(result)

@app.route('/api/models', methods=['GET'])
def get_models():
    """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    return jsonify({
        "models": agent.get_models(),
        "current_model": agent.current_model
    })

@app.route('/api/health', methods=['GET'])
def health_check():
    """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
    try:
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        return jsonify({
            "status": "healthy" if response.status_code == 200 else "unhealthy",
            "ollama_status": response.status_code
        })
    except:
        return jsonify({"status": "unreachable"})

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨Ollamaå¯¹è¯ç½‘é¡µ...")
    print(f"ğŸ“š å¯ç”¨æ¨¡å‹: {', '.join(agent.get_models())}")
    print("ğŸŒ è®¿é—® http://localhost:5000 å¼€å§‹èŠå¤©")
    app.run(debug=True, host='0.0.0.0', port=5000)